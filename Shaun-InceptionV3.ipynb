{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2DT04yiIXEq"
      },
      "source": [
        "# Source Code Notebook - InceptionV3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqKgtue0IXEs"
      },
      "source": [
        "## Google Colab Configs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQiRYFGMIXEt",
        "outputId": "a055f1ff-4600-4ec0-9921-b14e60411d9e"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkKHGcJBIXEt"
      },
      "source": [
        "## Image Conversion and Validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversion of JPG to JPEG\n",
        "\n",
        "```\n",
        "pip install opencv-python\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "DATA_DIR = \"dataset/AI Art vs Real Art/\" # Put unzipped files to the unzipped folder and change accordingly\n",
        "\n",
        "# For Colab:\n",
        "# DATA_DIR = \"/content/drive/MyDrive/dataset/AI Art vs Real Art\"\n",
        "def jpg_to_jpeg(data_dir):\n",
        "    for dir_name in os.listdir(data_dir):\n",
        "        if (dir_name != '.DS_Store'):\n",
        "            files = os.path.join(data_dir,dir_name)\n",
        "            for filepaths in os.listdir(files):\n",
        "                file_names = os.path.join(files,filepaths)\n",
        "                if file_names.endswith(\".jpg\") or file_names.endswith(\".JPG\"):\n",
        "                    img = cv2.imread(str(file_names))\n",
        "                    cv2.imwrite(file_names[0:-4]+\".jpeg\", img)\n",
        "                    os.remove(file_names)\n",
        "                    \n",
        "jpg_to_jpeg(data_dir=\"dataset/AI Art vs Real Art/AI Art\")\n",
        "jpg_to_jpeg(data_dir=\"dataset/AI Art vs Real Art/Real\")\n",
        "\n",
        "# jpg_to_jpeg(data_dir=\"/content/drive/MyDrive/dataset/AI Art vs Real Art/AI Art\")\n",
        "# jpg_to_jpeg(data_dir=\"/content/drive/MyDrive/dataset/AI Art vs Real Art/Real\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJfcwQRAIXEt"
      },
      "source": [
        "### Checking of the validity of Images in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvTfOiHZIXEt"
      },
      "outputs": [],
      "source": [
        "import imghdr\n",
        "IMAGE_EXTENSIONS = [\".png\", \".jpg\", \".jpeg\"]  # add there all your images file extensions\n",
        "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
        "for filepath in Path(DATA_DIR).rglob(\"*\"):\n",
        "    if filepath.suffix.lower() in IMAGE_EXTENSIONS:\n",
        "        img_type = imghdr.what(filepath)\n",
        "        if img_type is None:\n",
        "            print(f\"{filepath} is not an image\")\n",
        "            os.remove(filepath)\n",
        "        elif img_type not in img_type_accepted_by_tf:\n",
        "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddchwRzEIXEt"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56lYWURhIXEu"
      },
      "source": [
        "### Import Tensorflow and Keras and check on available GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDWAqon4IXEu",
        "outputId": "274299e1-0bcd-4a22-de56-5fbacc6cad33"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import platform\n",
        "import numpy as np\n",
        "print(f\"Python Platform: {platform.version()}\")\n",
        "print(f\"Python Version: {sys.version}\")\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n",
        "print()\n",
        "gpu = len(tf.config.list_physical_devices('GPU')) > 0\n",
        "print(f\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6bJUNwEIXEu"
      },
      "source": [
        "### Set constants for Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bV06lXmIXEv"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "HEIGHT = 256\n",
        "WIDTH = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## By Scratch Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Util Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_dataset(path):\n",
        "    all_files = [os.path.join(path, f) for f in os.listdir(path)]\n",
        "    valid_files = [f for f in all_files if f.split('.')[-1].lower() in img_type_accepted_by_tf]\n",
        "    return tf.data.Dataset.from_tensor_slices(valid_files)\n",
        "\n",
        "def split_dataset(dataset, train_size, val_size):\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    val_dataset = dataset.skip(train_size).take(val_size)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "def undersample_dataset(dataset, target_size):\n",
        "    return dataset.take(target_size)\n",
        "\n",
        "def load_and_preprocess_image(file_path):\n",
        "    file_extension = tf.strings.split(file_path, '.')[-1]\n",
        "    image = tf.io.read_file(file_path)\n",
        "\n",
        "    # Decode based on the file extension\n",
        "    if file_extension == 'png':\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "    elif file_extension == 'bmp':\n",
        "        image = tf.image.decode_bmp(image, channels=3)\n",
        "    elif file_extension == 'gif':\n",
        "        image = tf.image.decode_gif(image)\n",
        "        image = tf.squeeze(image, axis=0)  # Extract the first frame\n",
        "    else:  # Default to JPEG\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [HEIGHT, WIDTH])\n",
        "    return image\n",
        "\n",
        "def label_dataset(dataset, label):\n",
        "    return dataset.map(lambda x: (x, label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading and Shuffling Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AI_ART_PATH = 'dataset/AI Art vs Real Art/AI Art/AiArtData'\n",
        "REAL_ART_PATH = 'dataset/AI Art vs Real Art/Real/RealArt'\n",
        "\n",
        "ai_images = load_dataset(AI_ART_PATH)\n",
        "real_images = load_dataset(REAL_ART_PATH)\n",
        "\n",
        "ai_dataset = ai_images.shuffle(buffer_size=1000, seed=1337)\n",
        "real_dataset = real_images.shuffle(buffer_size=1000, seed=1337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Total Number of Samples per Label and Determining the Size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_of_ai = len(os.listdir(AI_ART_PATH))\n",
        "num_of_real = len(os.listdir(REAL_ART_PATH))\n",
        "print(f'Total Number of Images: {num_of_ai + num_of_real} \\nNumber of AI: {num_of_ai} \\nNumber of Real: {num_of_real}')\n",
        "\n",
        "ai_train_size = int(num_of_ai * 0.8) # 0.8 split\n",
        "ai_val_size = num_of_ai - ai_train_size\n",
        "\n",
        "real_train_size = int(num_of_real * 0.8) \n",
        "real_val_size = num_of_real - real_train_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and Validation Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ai_train_dataset, ai_val_dataset = split_dataset(ai_dataset, ai_train_size, ai_val_size)\n",
        "real_train_dataset, real_val_dataset = split_dataset(real_dataset, real_train_size, real_val_size)\n",
        "\n",
        "target_train_size = min(ai_train_size, real_train_size)\n",
        "target_val_size = min(ai_val_size, real_val_size)\n",
        "\n",
        "print(f'Target Sizes of Training: {target_train_size} for Train, and {target_val_size} for Validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Undersample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ai_train_dataset = undersample_dataset(ai_train_dataset, target_train_size)\n",
        "real_train_dataset = undersample_dataset(real_train_dataset, target_train_size)\n",
        "\n",
        "print(f'Train Sizes: {ai_train_dataset.cardinality()} and {real_train_dataset.cardinality()}')\n",
        "\n",
        "ai_val_dataset = undersample_dataset(ai_val_dataset, target_val_size)\n",
        "real_val_dataset = undersample_dataset(real_val_dataset, target_val_size)\n",
        "print(f'Validation Sizes: {ai_val_dataset.cardinality()} and {real_val_dataset.cardinality()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ai_train_dataset= ai_train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "real_train_dataset = real_train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ai_val_dataset =ai_val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "real_val_dataset = real_val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Label Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ai_train_dataset = label_dataset(ai_train_dataset, 0)\n",
        "real_train_dataset = label_dataset(real_train_dataset, 1)\n",
        "\n",
        "ai_val_dataset = label_dataset(ai_val_dataset, 0)\n",
        "real_val_dataset = label_dataset(real_val_dataset, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combine Training Datasets and Validation Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = ai_train_dataset.concatenate(real_train_dataset)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1000)\n",
        "print(f'Training Dataset Size: {train_dataset.cardinality()}')\n",
        "\n",
        "val_dataset = ai_val_dataset.concatenate(real_val_dataset)\n",
        "val_dataset = val_dataset.shuffle(buffer_size=1000)\n",
        "print(f'Validation Dataset Size: {val_dataset.cardinality()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeVbub8vIXEv"
      },
      "source": [
        "### Display Sample Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "yaIlOCwZIXEv",
        "outputId": "ff70d863-71e8-4b36-f429-562e5a5b147b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to display images from a dataset\n",
        "def display_binary_images(dataset, class_names):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for images, labels in dataset.take(1):\n",
        "        for i in range(9):\n",
        "            ax = plt.subplot(3, 3, i + 1)\n",
        "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "            plt.title(class_names[int(labels[i].numpy())])\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "class_names = ['AI Art', 'Real Art']\n",
        "\n",
        "# Display images from the balanced training dataset\n",
        "display_binary_images(train_dataset, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV594AkxIXEw"
      },
      "source": [
        "### Rescale\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "877JPExJIXEw"
      },
      "source": [
        "### Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI2wGd84IXEw"
      },
      "outputs": [],
      "source": [
        "augmentation_layers = [\n",
        "    keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    keras.layers.RandomRotation(0.2),\n",
        "]\n",
        "\n",
        "def data_augmentation(x):\n",
        "    for layer in augmentation_layers:\n",
        "        x = layer(x)\n",
        "    return x\n",
        "\n",
        "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hbC-nK6IXEw"
      },
      "source": [
        "### Prefetch Data for Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzXniArhIXEw"
      },
      "outputs": [],
      "source": [
        "from tensorflow import data as tf_data\n",
        "\n",
        "train_dataset = train_dataset.prefetch(tf_data.AUTOTUNE).cache()\n",
        "val_dataset = val_dataset.prefetch(tf_data.AUTOTUNE).cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBmSMH8mIXEw"
      },
      "source": [
        "### Display Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "BEv5-zL8IXEw",
        "outputId": "c366bb16-9565-4d66-b325-6af8993ef061"
      },
      "outputs": [],
      "source": [
        "for images, labels in train_dataset.take(1):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    first_image = images[0]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        augmented_image = data_augmentation(np.expand_dims(first_image, 0))\n",
        "        plt.imshow(np.array(augmented_image[0]).astype(\"int32\"))\n",
        "        plt.title(int(labels[0]))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o07uiLZhIXEw"
      },
      "source": [
        "## Importing InceptionV3 and Base Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGc_Pv6AIXEw"
      },
      "source": [
        "### Import InceptionV3 as our base model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1mthDNOIXEw"
      },
      "outputs": [],
      "source": [
        "base_model = keras.applications.InceptionV3(\n",
        "    include_top=False, # Do not include the final layer, which classifies images\n",
        "    weights=\"imagenet\",\n",
        "    pooling='avg',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc3kqJorIXEw"
      },
      "source": [
        "### Make base model non-trainable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k985m4dMIXEw"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcvQNuETIXEx"
      },
      "source": [
        "## Fine-Tuning the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-liF8W4IXEx"
      },
      "source": [
        "### Util Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKcID7NbIXEx"
      },
      "outputs": [],
      "source": [
        "# Dynamic Learning Rate\n",
        "def lr_schedule(epoch):\n",
        "    initial_lr = 0.001\n",
        "    drop = 0.1\n",
        "    epochs_drop = 10\n",
        "    lr = initial_lr * np.power(drop, np.floor((1 + epoch)\n",
        "        / epochs_drop))\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKXU708hIXEy"
      },
      "outputs": [],
      "source": [
        "stop = keras.callbacks.EarlyStopping(\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    monitor=\"val_loss\",\n",
        "    start_from_epoch=5,\n",
        "    verbose=1)\n",
        "\n",
        "callbacks = [\n",
        "    stop,\n",
        "    keras.callbacks.LearningRateScheduler(lr_schedule),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwyliiiOIXEy"
      },
      "source": [
        "### Create new Model on Top\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otT5oxmeIXEy"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "# Starting layers\n",
        "inputs = keras.Input(shape=(HEIGHT, WIDTH, 3))\n",
        "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
        "x = scale_layer(inputs)\n",
        "\n",
        "x = base_model(inputs, training=False) # run in inference mode\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(2056, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)  \n",
        "x = layers.Dense(512, activation='relu')(x)  \n",
        "x = layers.Dropout(0.2)(x) \n",
        "x = layers.Dense(256, activation='relu')(x)  \n",
        "x = layers.Dropout(0.2)(x) \n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ti5GfMuIXEy"
      },
      "source": [
        "### Compile the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-seid4-IXEy",
        "outputId": "7354f6a4-15ab-40ca-c875-0fd297d57e71"
      },
      "outputs": [],
      "source": [
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary(show_trainable=True)\n",
        "\n",
        "stop = keras.callbacks.EarlyStopping(\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    monitor=\"val_loss\",\n",
        "    start_from_epoch=5,\n",
        "    verbose=1)\n",
        "\n",
        "callbacks = [\n",
        "    stop,\n",
        "    keras.callbacks.LearningRateScheduler(lr_schedule),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY1TgNn_IXEy"
      },
      "source": [
        "### Train the Top Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUXNdrJXIXEy",
        "outputId": "7e941060-ce0b-40d4-eba4-6b66c709dbca"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    metrics= [keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "print(\"Fitting the top layer of the model\")\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=EPOCHS,\n",
        "          validation_data=val_dataset,\n",
        "          callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X53TW3iCIXEy"
      },
      "source": [
        "## Fine Tuning the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrS_YBA8IXEy"
      },
      "source": [
        "### Util Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvCEqlHnIXEz"
      },
      "outputs": [],
      "source": [
        "# Dynamic Learning Rate\n",
        "def fine_tuned_lr_schedule(epoch):\n",
        "    initial_lr = 0.00001\n",
        "    drop = 0.1\n",
        "    epochs_drop = 10\n",
        "    lr = initial_lr * np.power(drop, np.floor((1 + epoch)\n",
        "        / epochs_drop))\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1gp-WJNIXEz"
      },
      "outputs": [],
      "source": [
        "stop = keras.callbacks.EarlyStopping(\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    monitor=\"val_loss\",\n",
        "    start_from_epoch=5,\n",
        "    verbose=1)\n",
        "\n",
        "callbacks = [\n",
        "    stop,\n",
        "    keras.callbacks.LearningRateScheduler(fine_tuned_lr_schedule),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyXHYG1PIXEz"
      },
      "source": [
        "### Unfreeze Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USd0Rsp6IXEz"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D):\n",
        "        layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVKUsNd-IXEz",
        "outputId": "f35d1128-1cdd-499c-baa9-63440762baa0"
      },
      "outputs": [],
      "source": [
        "model.summary(show_trainable=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(learning_rate=0.00001),\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    metrics= [keras.metrics.BinaryAccuracy()],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKY5M2mWIXEz",
        "outputId": "03c8abd7-c24d-4233-ba55-59bb24e6a197"
      },
      "outputs": [],
      "source": [
        "print(\"Fitting the end-end model\")\n",
        "fine_tuned_model = model.fit(train_dataset,\n",
        "          epochs=EPOCHS,\n",
        "          validation_data=val_dataset,\n",
        "          callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r4Qu9h8IXEz"
      },
      "source": [
        "## Evaluation of the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY4iT2umIXEz"
      },
      "source": [
        "### Predicting a Specific Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "WL8Is-5hIXEz",
        "outputId": "d325999c-8199-4556-e565-d70d27c9bf3c"
      },
      "outputs": [],
      "source": [
        "img_path = \"dataset/AI Art vs Real Art/Real/RealArt/-man-sits-with-a-woman-on-her-phone-at-a-table-while-looking-at-a-computer_l.jpeg\"\n",
        "# img_path = \"/content/drive/MyDrive/dataset/AI Art vs Real Art/Real/RealArt/-man-sits-with-a-woman-on-her-phone-at-a-table-while-looking-at-a-computer_l.jpeg\"\n",
        "\n",
        "img = keras.preprocessing.image.load_img(img_path,\n",
        "                                            target_size=(HEIGHT, WIDTH))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(img_array)[0]\n",
        "\n",
        "print(f\"Predictions: {predictions}\")\n",
        "\n",
        "# Interpret the prediction (assuming binary classification with 0 for Real Art and 1 for AI Art)\n",
        "# Ensure predictions is in the correct format\n",
        "if len(predictions.shape) == 1:\n",
        "    predicted_class = 'Real Art' if predictions[0] > 0.5 else 'AI Art'\n",
        "else:\n",
        "    predicted_class = 'Real Art' if predictions[0][0] > 0.5 else 'AI Art'\n",
        "\n",
        "# Create a string with the predicted label\n",
        "result_string = f'The predicted class for the image {img_path} is: {predicted_class}'\n",
        "print(result_string)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg5KpEcUIXEz"
      },
      "source": [
        "### Predicting a Random Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "7PzE0GmLIXEz",
        "outputId": "40de210e-889e-4fd5-beab-f5065a6578e8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "folder_number = random.randint(1, 2)  # Generate a random number between 1-3\n",
        "if folder_number == 1:\n",
        "    dataset_dir = \"dataset/AI Art vs Real Art/AI Art/AiArtData\"\n",
        "else:\n",
        "    dataset_dir = \"dataset/AI Art vs Real Art/Real/RealArt\"\n",
        "\n",
        "# if folder_number == 1:\n",
        "#     dataset_dir = \"/content/drive/MyDrive/dataset/AI Art vs Real Art/AI Art/AiArtData\"\n",
        "# else:\n",
        "#     dataset_dir = \"/content/drive/MyDrive/dataset/AI Art vs Real Art/Real/RealArt\"\n",
        "print(dataset_dir)\n",
        "file_list = os.listdir(dataset_dir)\n",
        "\n",
        "random_file = random.choice(file_list)\n",
        "image_path = os.path.join(dataset_dir, random_file)\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(image_path,\n",
        "                                            target_size=(HEIGHT, WIDTH))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(img_array)[0]\n",
        "\n",
        "print(f\"Predictions: {predictions}\")\n",
        "\n",
        "# Interpret the prediction (assuming binary classification with 0 for Real Art and 1 for AI Art)\n",
        "# Ensure predictions is in the correct format\n",
        "if len(predictions.shape) == 1:\n",
        "    predicted_class = 'Real Art' if predictions[0] > 0.5 else 'AI Art'\n",
        "else:\n",
        "    predicted_class = 'Real Art' if predictions[0][0] > 0.5 else 'AI Art'\n",
        "\n",
        "# Create a string with the predicted label\n",
        "result_string = f'The predicted class for the image {random_file} is: {predicted_class}'\n",
        "print(result_string)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDzwIgT7IXE0"
      },
      "source": [
        "### Visualization in terms of Epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "DLpDEMzPIXE0",
        "outputId": "80a42c28-3c00-4c8e-9847-1cacb5aafeb0"
      },
      "outputs": [],
      "source": [
        "acc = fine_tuned_model.history['binary_accuracy']\n",
        "val_acc = fine_tuned_model.history['val_binary_accuracy']\n",
        "\n",
        "loss = fine_tuned_model.history['loss']\n",
        "val_loss = fine_tuned_model.history['val_loss']\n",
        "if stop.stopped_epoch != 0:\n",
        "    epochs_range = range(stop.stopped_epoch+1)\n",
        "else:\n",
        "    epochs_range = range(EPOCHS)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
