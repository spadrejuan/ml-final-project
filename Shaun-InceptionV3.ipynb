{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2DT04yiIXEq"
      },
      "source": [
        "# Source Code Notebook - InceptionV3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqKgtue0IXEs"
      },
      "source": [
        "## Google Colab Configs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQiRYFGMIXEt",
        "outputId": "d416b81a-bd31-49d7-f8b2-fa4f56a82120"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkKHGcJBIXEt"
      },
      "source": [
        "## Image Conversion and Validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T01r58DC0fD"
      },
      "source": [
        "### Conversion of JPG to JPEG\n",
        "\n",
        "```\n",
        "pip install opencv-python\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXmARsPMC0fD"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "# DATA_DIR = \"dataset/AI Art vs Real Art/\" # Put unzipped files to the unzipped folder and change accordingly\n",
        "\n",
        "# For Colab:\n",
        "DATA_DIR = \"/content/drive/MyDrive/dataset/AI Art vs Real Art\"\n",
        "def jpg_to_jpeg(data_dir):\n",
        "    for dir_name in os.listdir(data_dir):\n",
        "        if (dir_name != '.DS_Store'):\n",
        "            files = os.path.join(data_dir,dir_name)\n",
        "            for filepaths in os.listdir(files):\n",
        "                file_names = os.path.join(files,filepaths)\n",
        "                if file_names.endswith(\".jpg\") or file_names.endswith(\".JPG\"):\n",
        "                    img = cv2.imread(str(file_names))\n",
        "                    cv2.imwrite(file_names[0:-4]+\".jpeg\", img)\n",
        "                    os.remove(file_names)\n",
        "\n",
        "# jpg_to_jpeg(data_dir=\"dataset/AI Art vs Real Art/AI Art\")\n",
        "# jpg_to_jpeg(data_dir=\"dataset/AI Art vs Real Art/Real\")\n",
        "\n",
        "jpg_to_jpeg(data_dir=\"/content/drive/MyDrive/dataset/AI Art vs Real Art/AI Art\")\n",
        "jpg_to_jpeg(data_dir=\"/content/drive/MyDrive/dataset/AI Art vs Real Art/Real\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJfcwQRAIXEt"
      },
      "source": [
        "### Checking of the validity of Images in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvTfOiHZIXEt"
      },
      "outputs": [],
      "source": [
        "import imghdr\n",
        "IMAGE_EXTENSIONS = [\".png\", \".jpg\", \".jpeg\"]  # add there all your images file extensions\n",
        "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
        "for filepath in Path(DATA_DIR).rglob(\"*\"):\n",
        "    if filepath.suffix.lower() in IMAGE_EXTENSIONS:\n",
        "        img_type = imghdr.what(filepath)\n",
        "        if img_type is None:\n",
        "            print(f\"{filepath} is not an image\")\n",
        "            os.remove(filepath)\n",
        "        elif img_type not in img_type_accepted_by_tf:\n",
        "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddchwRzEIXEt"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56lYWURhIXEu"
      },
      "source": [
        "### Import Tensorflow and Keras and check on available GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDWAqon4IXEu",
        "outputId": "36877fad-41a7-4b69-a88a-32111a19c8f9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import platform\n",
        "import numpy as np\n",
        "print(f\"Python Platform: {platform.version()}\")\n",
        "print(f\"Python Version: {sys.version}\")\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n",
        "print()\n",
        "gpu = len(tf.config.list_physical_devices('GPU')) > 0\n",
        "print(f\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6bJUNwEIXEu"
      },
      "source": [
        "### Set constants for Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bV06lXmIXEv"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "HEIGHT = 256\n",
        "WIDTH = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTR0CAn9C0fF"
      },
      "source": [
        "## By Scratch Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpz12S4tC0fF"
      },
      "source": [
        "### Util Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMdiN6RZC0fF"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path):\n",
        "    all_files = [os.path.join(path, f) for f in os.listdir(path)]\n",
        "    valid_files = [f for f in all_files if f.split('.')[-1].lower() in img_type_accepted_by_tf]\n",
        "    return tf.data.Dataset.from_tensor_slices(valid_files)\n",
        "\n",
        "def split_dataset(dataset, train_size, val_size):\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    val_dataset = dataset.skip(train_size).take(val_size)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "def undersample_dataset(dataset, target_size):\n",
        "    return dataset.take(target_size)\n",
        "\n",
        "def load_and_preprocess_image(file_path):\n",
        "    file_extension = tf.strings.split(file_path, '.')[-1]\n",
        "    image = tf.io.read_file(file_path)\n",
        "\n",
        "    # Decode based on the file extension\n",
        "    if file_extension == 'png':\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "    elif file_extension == 'bmp':\n",
        "        image = tf.image.decode_bmp(image, channels=3)\n",
        "    elif file_extension == 'gif':\n",
        "        image = tf.image.decode_gif(image)\n",
        "        image = tf.squeeze(image, axis=0)  # Extract the first frame\n",
        "    else:  # Default to JPEG\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [HEIGHT, WIDTH])\n",
        "    return image\n",
        "\n",
        "def label_dataset(dataset, label):\n",
        "    return dataset.map(lambda x: (x, label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sm1fNOvC0fF"
      },
      "source": [
        "### Loading and Shuffling Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw8frwxDC0fG"
      },
      "outputs": [],
      "source": [
        "# AI_ART_PATH = 'dataset/AI Art vs Real Art/AI Art/AiArtData'\n",
        "# REAL_ART_PATH = 'dataset/AI Art vs Real Art/Real/RealArt'\n",
        "AI_ART_PATH = '/content/drive/MyDrive/dataset/AI Art vs Real Art/AI Art/AiArtData'\n",
        "REAL_ART_PATH = '/content/drive/MyDrive/dataset/AI Art vs Real Art/Real/RealArt'\n",
        "ai_images = load_dataset(AI_ART_PATH)\n",
        "real_images = load_dataset(REAL_ART_PATH)\n",
        "\n",
        "ai_dataset = ai_images.shuffle(buffer_size=1000, seed=1337)\n",
        "real_dataset = real_images.shuffle(buffer_size=1000, seed=1337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfYVNh5PC0fG"
      },
      "source": [
        "### Total Number of Samples per Label and Determining the Size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBB5KuiZC0fG",
        "outputId": "2f8110e6-cbf2-4b67-d907-d289d598f52a"
      },
      "outputs": [],
      "source": [
        "num_of_ai = len(os.listdir(AI_ART_PATH))\n",
        "num_of_real = len(os.listdir(REAL_ART_PATH))\n",
        "print(f'Total Number of Images: {num_of_ai + num_of_real} \\nNumber of AI: {num_of_ai} \\nNumber of Real: {num_of_real}')\n",
        "\n",
        "ai_train_size = int(num_of_ai * 0.8) # 0.8 split\n",
        "ai_val_size = num_of_ai - ai_train_size\n",
        "\n",
        "real_train_size = int(num_of_real * 0.8)\n",
        "real_val_size = num_of_real - real_train_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPVRCHW8C0fG"
      },
      "source": [
        "### Train and Validation Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7G8gYhmC0fG",
        "outputId": "2281bc05-8c9b-47c0-b881-a5c7a30af7aa"
      },
      "outputs": [],
      "source": [
        "ai_train_dataset, ai_val_dataset = split_dataset(ai_dataset, ai_train_size, ai_val_size)\n",
        "real_train_dataset, real_val_dataset = split_dataset(real_dataset, real_train_size, real_val_size)\n",
        "\n",
        "target_train_size = min(ai_train_size, real_train_size)\n",
        "target_val_size = min(ai_val_size, real_val_size)\n",
        "\n",
        "print(f'Target Sizes of Training: {target_train_size} for Train, and {target_val_size} for Validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al0T6rzRC0fH"
      },
      "source": [
        "### Undersample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToTCo7PHC0fH"
      },
      "outputs": [],
      "source": [
        "ai_train_dataset = undersample_dataset(ai_train_dataset, target_train_size)\n",
        "real_train_dataset = undersample_dataset(real_train_dataset, target_train_size)\n",
        "\n",
        "ai_val_dataset = undersample_dataset(ai_val_dataset, target_val_size)\n",
        "real_val_dataset = undersample_dataset(real_val_dataset, target_val_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aswKFs7WC0fH"
      },
      "source": [
        "### Apply Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLm3oNMsC0fI"
      },
      "outputs": [],
      "source": [
        "ai_train_dataset= ai_train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "real_train_dataset = real_train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ai_val_dataset =ai_val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "real_val_dataset = real_val_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8upZ6nJkC0fI"
      },
      "source": [
        "### Label Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nTTic_0C0fI"
      },
      "outputs": [],
      "source": [
        "ai_train_dataset = label_dataset(ai_train_dataset, 0)\n",
        "real_train_dataset = label_dataset(real_train_dataset, 1)\n",
        "\n",
        "ai_val_dataset = label_dataset(ai_val_dataset, 0)\n",
        "real_val_dataset = label_dataset(real_val_dataset, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keoHlWIWC0fI"
      },
      "source": [
        "### Combine Training Datasets and Validation Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4oLw1A8C0fI"
      },
      "outputs": [],
      "source": [
        "train_dataset = ai_train_dataset.concatenate(real_train_dataset)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1000)\n",
        "\n",
        "val_dataset = ai_val_dataset.concatenate(real_val_dataset)\n",
        "val_dataset = val_dataset.shuffle(buffer_size=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnzXkrn0C0fI"
      },
      "source": [
        "### Batch Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO5Oq8XHC0fI"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeVbub8vIXEv"
      },
      "source": [
        "### Display Sample Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "yaIlOCwZIXEv",
        "outputId": "4d60b0d6-1089-4748-f1e4-b5d50092f2e5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to display images from a dataset\n",
        "def display_binary_images(dataset, class_names):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for images, labels in dataset.take(1):\n",
        "        for i in range(9):\n",
        "            ax = plt.subplot(3, 3, i + 1)\n",
        "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "            plt.title(class_names[int(labels[i].numpy())])\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "class_names = ['AI Art', 'Real Art']\n",
        "\n",
        "# Display images from the balanced training dataset\n",
        "display_binary_images(train_dataset, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hbC-nK6IXEw"
      },
      "source": [
        "### Prefetch Data for Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzXniArhIXEw"
      },
      "outputs": [],
      "source": [
        "from tensorflow import data as tf_data\n",
        "\n",
        "train_dataset = train_dataset.prefetch(tf_data.AUTOTUNE).cache()\n",
        "val_dataset = val_dataset.prefetch(tf_data.AUTOTUNE).cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o07uiLZhIXEw"
      },
      "source": [
        "## Importing InceptionV3 and Base Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGc_Pv6AIXEw"
      },
      "source": [
        "### Import InceptionV3 as our base model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1mthDNOIXEw"
      },
      "outputs": [],
      "source": [
        "base_model = keras.applications.InceptionV3(\n",
        "    include_top=False, # Do not include the final layer, which classifies images\n",
        "    weights=\"imagenet\",\n",
        "    pooling='max',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc3kqJorIXEw"
      },
      "source": [
        "### Make base model non-trainable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k985m4dMIXEw"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcvQNuETIXEx"
      },
      "source": [
        "## Adding New Layers to Base Model and Initial Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-liF8W4IXEx"
      },
      "source": [
        "### Util Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKcID7NbIXEx"
      },
      "outputs": [],
      "source": [
        "# Dynamic Learning Rate\n",
        "def lr_schedule(epoch):\n",
        "    initial_lr = 0.001\n",
        "    drop = 0.1\n",
        "    epochs_drop = 10\n",
        "    lr = initial_lr * np.power(drop, np.floor((1 + epoch)\n",
        "        / epochs_drop))\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKXU708hIXEy"
      },
      "outputs": [],
      "source": [
        "stop = keras.callbacks.EarlyStopping(\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    monitor=\"val_loss\",\n",
        "    start_from_epoch=5,\n",
        "    verbose=1)\n",
        "\n",
        "callbacks = [\n",
        "    stop,\n",
        "    keras.callbacks.LearningRateScheduler(lr_schedule),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T2jeV76lnjw"
      },
      "source": [
        "### Creating a Custom Callback for Precision, Recall, F1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_N-n7KFlnjw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "class F1ScoreCallback(keras.callbacks.Callback):\n",
        "  def __init__(self, validation_data):\n",
        "    self.validation_data = validation_data\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    x_val, y_val = self.validation_data\n",
        "    y_pred = self.model.predict(x_val)\n",
        "    y_pred = y_pred.round()  # Threshold for classification problems\n",
        "\n",
        "    # Calculate TP, FP, FN\n",
        "    tp = tf.reduce_sum(tf.cast(y_val * y_pred, 'float'), axis=0)\n",
        "    fp = tf.reduce_sum(tf.cast((1 - y_val) * y_pred, 'float'), axis=0)\n",
        "    fn = tf.reduce_sum(tf.cast(y_val * (1 - y_pred), 'float'), axis=0)\n",
        "\n",
        "    # Precision and recall with epsilon to avoid division by zero\n",
        "    precision = tp / (tp + fp + keras.backend.epsilon())\n",
        "    recall = tp / (tp + fn + keras.backend.epsilon())\n",
        "\n",
        "    # F1 score with epsilon and handling NaNs\n",
        "    f1 = 2 * precision * recall / (precision + recall + keras.backend.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f'F1 Score on Validation Set at Epoch {epoch + 1}: {f1.numpy().mean():.4f}')\n",
        "    print(f'True Positives: {tp.numpy().mean():.0f}')\n",
        "    print(f'False Positives: {fp.numpy().mean():.0f}')\n",
        "    print(f'False Negatives: {fn.numpy().mean():.0f}')\n",
        "    print(f'Precision: {precision.numpy().mean():.4f}')\n",
        "    print(f'Recall: {recall.numpy().mean():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwyliiiOIXEy"
      },
      "source": [
        "### Create new Model on Top\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otT5oxmeIXEy"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "# Starting layers\n",
        "inputs = keras.Input(shape=(HEIGHT, WIDTH, 3))\n",
        "x = keras.applications.inception_v3.preprocess_input(inputs)\n",
        "x = base_model(inputs, training=False) # run in inference mode\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(2056, activation='relu')(x)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ti5GfMuIXEy"
      },
      "source": [
        "### Compile the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-seid4-IXEy",
        "outputId": "021102d3-5eb1-4298-e51b-c5b7677253bd"
      },
      "outputs": [],
      "source": [
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary(show_trainable=True)\n",
        "\n",
        "stop = keras.callbacks.EarlyStopping(\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    monitor=\"val_loss\",\n",
        "    start_from_epoch=5,\n",
        "    verbose=1)\n",
        "callbacks = [\n",
        "    stop,\n",
        "    keras.callbacks.LearningRateScheduler(lr_schedule),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY1TgNn_IXEy"
      },
      "source": [
        "### Train the Top Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUXNdrJXIXEy",
        "outputId": "e38bafa0-6c3a-483f-862e-dfc64efdc305"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "f1_callback = F1ScoreCallback(val_dataset)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    metrics= [\n",
        "        keras.metrics.BinaryAccuracy(threshold=0.5),\n",
        "        f1_callback\n",
        "    ],\n",
        ")\n",
        "print(\"Fitting the top layer of the model\")\n",
        "model.fit(train_dataset,\n",
        "          epochs=EPOCHS,\n",
        "          validation_data=val_dataset,\n",
        "          callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X53TW3iCIXEy"
      },
      "source": [
        "## Fine Tuning the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrS_YBA8IXEy"
      },
      "source": [
        "### Util Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvCEqlHnIXEz"
      },
      "outputs": [],
      "source": [
        "# Dynamic Learning Rate\n",
        "def fine_tuned_lr_schedule(epoch):\n",
        "    initial_lr = 0.00001\n",
        "    drop = 0.1\n",
        "    epochs_drop = 10\n",
        "    lr = initial_lr * np.power(drop, np.floor((1 + epoch)\n",
        "        / epochs_drop))\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1gp-WJNIXEz"
      },
      "outputs": [],
      "source": [
        "stop = keras.callbacks.EarlyStopping(\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    monitor=\"val_loss\",\n",
        "    start_from_epoch=5,\n",
        "    verbose=1)\n",
        "callbacks = [\n",
        "    stop,\n",
        "    keras.callbacks.LearningRateScheduler(fine_tuned_lr_schedule),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyXHYG1PIXEz"
      },
      "source": [
        "### Unfreeze Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USd0Rsp6IXEz"
      },
      "outputs": [],
      "source": [
        "# for layer in base_model.layers:\n",
        "#     if isinstance(layer, keras.layers.Conv2D):\n",
        "#         layer.trainable = True\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVKUsNd-IXEz",
        "outputId": "f36f38d3-a493-44fd-dd26-54727a88f741"
      },
      "outputs": [],
      "source": [
        "model.summary(show_trainable=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(learning_rate=0.00001),\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    metrics= [\n",
        "        keras.metrics.BinaryAccuracy(threshold=0.5),\n",
        "        f1_callback\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKY5M2mWIXEz",
        "outputId": "24b9c6d0-86a2-4b87-a2e5-e5ff0f019c25"
      },
      "outputs": [],
      "source": [
        "print(\"Fitting the end-end model\")\n",
        "fine_tuned_model = model.fit(train_dataset,\n",
        "          epochs=EPOCHS,\n",
        "          validation_data=val_dataset,\n",
        "          callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r4Qu9h8IXEz"
      },
      "source": [
        "## Evaluation of the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY4iT2umIXEz"
      },
      "source": [
        "### Predicting a Specific Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "WL8Is-5hIXEz",
        "outputId": "0e609145-6bbf-45f8-d4a6-de2c14d8c313"
      },
      "outputs": [],
      "source": [
        "# img_path = \"dataset/AI Art vs Real Art/Real/RealArt/-man-sits-with-a-woman-on-her-phone-at-a-table-while-looking-at-a-computer_l.jpeg\"\n",
        "img_path = \"/content/drive/MyDrive/dataset/AI Art vs Real Art/Real/RealArt/-man-sits-with-a-woman-on-her-phone-at-a-table-while-looking-at-a-computer_l.jpeg\"\n",
        "\n",
        "img = keras.preprocessing.image.load_img(img_path,\n",
        "                                            target_size=(HEIGHT, WIDTH))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(img_array)[0]\n",
        "\n",
        "print(f\"Predictions: {predictions}\")\n",
        "\n",
        "\n",
        "if len(predictions.shape) == 1:\n",
        "    predicted_class = 'Real Art' if predictions[0] > 0.5 else 'AI Art'\n",
        "else:\n",
        "    predicted_class = 'Real Art' if predictions[0][0] > 0.5 else 'AI Art'\n",
        "\n",
        "result_string = f'The predicted class for the image {img_path} is: {predicted_class}'\n",
        "print(result_string)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg5KpEcUIXEz"
      },
      "source": [
        "### Predicting a Random Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "7PzE0GmLIXEz",
        "outputId": "ef3829da-2ad8-4bfa-d56a-708644ccccaa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "folder_number = random.randint(1, 2)  # Generate a random number between 1-3\n",
        "# if folder_number == 1:\n",
        "#     dataset_dir = \"dataset/AI Art vs Real Art/AI Art/AiArtData\"\n",
        "# else:\n",
        "#     dataset_dir = \"dataset/AI Art vs Real Art/Real/RealArt\"\n",
        "\n",
        "if folder_number == 1:\n",
        "    dataset_dir = \"/content/drive/MyDrive/dataset/AI Art vs Real Art/AI Art/AiArtData\"\n",
        "else:\n",
        "    dataset_dir = \"/content/drive/MyDrive/dataset/AI Art vs Real Art/Real/RealArt\"\n",
        "print(dataset_dir)\n",
        "file_list = os.listdir(dataset_dir)\n",
        "\n",
        "random_file = random.choice(file_list)\n",
        "image_path = os.path.join(dataset_dir, random_file)\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(image_path,\n",
        "                                            target_size=(HEIGHT, WIDTH))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(img_array)[0]\n",
        "\n",
        "print(f\"Predictions: {predictions}\")\n",
        "\n",
        "\n",
        "if len(predictions.shape) == 1:\n",
        "    predicted_class = 'Real Art' if predictions[0] > 0.5 else 'AI Art'\n",
        "else:\n",
        "    predicted_class = 'Real Art' if predictions[0][0] > 0.5 else 'AI Art'\n",
        "\n",
        "result_string = f'The predicted class for the image {random_file} is: {predicted_class}'\n",
        "print(result_string)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDzwIgT7IXE0"
      },
      "source": [
        "### Visualization in terms of Epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "DLpDEMzPIXE0",
        "outputId": "7295c12a-470e-4885-84ea-af255d9b436e"
      },
      "outputs": [],
      "source": [
        "acc = fine_tuned_model.history['f1_score']\n",
        "val_acc = fine_tuned_model.history['val_f1_score']\n",
        "\n",
        "loss = fine_tuned_model.history['loss']\n",
        "val_loss = fine_tuned_model.history['val_loss']\n",
        "if stop.stopped_epoch != 0:\n",
        "    epochs_range = range(stop.stopped_epoch+1)\n",
        "else:\n",
        "    epochs_range = range(EPOCHS)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
