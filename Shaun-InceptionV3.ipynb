{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Code Notebook - InceptionV3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import Drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Conversion and Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of JPG to JPEG\n",
    "\n",
    "```\n",
    "pip install opencv-python\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "DATA_DIR = \"dataset/AI Art vs Real Art/\" # Put unzipped files to the unzipped folder and change accordingly\n",
    "\n",
    "# For Colab:\n",
    "# DATA_DIR = \"drive/MyDrive/dataset/AI Art vs Real Art/\"\n",
    "def jpg_to_jpeg(data_dir):\n",
    "    for dir_name in os.listdir(data_dir):\n",
    "        if (dir_name != '.DS_Store'):\n",
    "            files = os.path.join(data_dir,dir_name)\n",
    "            for filepaths in os.listdir(files):\n",
    "                file_names = os.path.join(files,filepaths)\n",
    "                if file_names.endswith(\".jpg\") or file_names.endswith(\".JPG\"):\n",
    "                    img = cv2.imread(str(file_names))\n",
    "                    cv2.imwrite(file_names[0:-4]+\".jpeg\", img)\n",
    "                    os.remove(file_names)\n",
    "                    \n",
    "jpg_to_jpeg(data_dir=\"dataset/AI Art vs Real Art/AI Art\")\n",
    "jpg_to_jpeg(data_dir=\"dataset/AI Art vs Real Art/Real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking of the validity of Images in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imghdr\n",
    "IMAGE_EXTENSIONS = [\".png\", \".jpg\", \".jpeg\"]  # add there all your images file extensions\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(DATA_DIR).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in IMAGE_EXTENSIONS:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        if img_type is None:\n",
    "            print(f\"{filepath} is not an image\")\n",
    "            os.remove(filepath)\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Tensorflow and Keras and check on available GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import platform\n",
    "import numpy as np\n",
    "print(f\"Python Platform: {platform.version()}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print()\n",
    "gpu = len(tf.config.list_physical_devices('GPU')) > 0\n",
    "print(f\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set constants for Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "IMAGE_SIZE = (HEIGHT, WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Keras' Preprocessing modules to split data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    label_mode='binary',\n",
    "    labels='inferred',\n",
    "    color_mode='rgb',\n",
    "    directory=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    seed=1337,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "val_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    label_mode='binary',\n",
    "    labels='inferred',\n",
    "    color_mode='rgb',\n",
    "    directory=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    seed=1337,\n",
    "    validation_split=0.2, # use 20% as validation\n",
    "    subset=\"validation\",\n",
    "    verbose=True,\n",
    ")\n",
    "# The target labels\n",
    "class_names = train_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Sample Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_binary_images(dataset, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            plt.title(class_names[int(labels[i].numpy())])\n",
    "            plt.axis(\"off\")\n",
    "display_binary_images(train_dataset, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation_layers = [\n",
    "#     keras.layers.RandomFlip(\"horizontal\"),\n",
    "#     keras.layers.RandomRotation(0.1),\n",
    "# ]\n",
    "\n",
    "\n",
    "# def data_augmentation(x):\n",
    "#     for layer in augmentation_layers:\n",
    "#         x = layer(x)\n",
    "#     return x\n",
    "\n",
    "\n",
    "# train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefetch Data for Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import data as tf_data\n",
    "\n",
    "train_dataset = train_dataset.prefetch(tf_data.AUTOTUNE).cache()\n",
    "val_dataset = val_dataset.prefetch(tf_data.AUTOTUNE).cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images, labels in train_dataset.take(1):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     first_image = images[0]\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         augmented_image = data_augmentation(np.expand_dims(first_image, 0))\n",
    "#         plt.imshow(np.array(augmented_image[0]).astype(\"int32\"))\n",
    "#         plt.title(int(labels[0]))\n",
    "#         plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing InceptionV3 and Base Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import InceptionV3 as our base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.InceptionV3(\n",
    "    include_top=False, # Do not include the final layer, which classifies images\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(HEIGHT, WIDTH, 3),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make base model non-trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new Model on Top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "# Starting layers\n",
    "inputs = keras.Input(shape=(HEIGHT, WIDTH, 3))\n",
    "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(inputs)\n",
    "\n",
    "x = base_model(inputs, training=False) # run in inference mode\n",
    "\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary(show_trainable=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics= [keras.metrics.BinaryAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Top Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Learning Rate\n",
    "def lr_schedule(epoch, input_lr):\n",
    "    drop = 0.1\n",
    "    epochs_drop = 8\n",
    "    lr = input_lr * np.power(drop, np.floor((1 + epoch) \n",
    "        / epochs_drop))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True, \n",
    "    monitor=\"val_loss\", \n",
    "    start_from_epoch=15, \n",
    "    verbose=1)\n",
    "\n",
    "callbacks = [\n",
    "    stop,\n",
    "    # keras.callbacks.LearningRateScheduler(lr_schedule),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics= [keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "print(\"Fitting the top layer of the model\")\n",
    "\n",
    "model.fit(train_dataset, \n",
    "          epochs=EPOCHS, \n",
    "          validation_data=val_dataset,\n",
    "          callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "model.summary(show_trainable=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics= [keras.metrics.BinaryAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting the end-end model\")\n",
    "fine_tuned_model = model.fit(train_dataset, \n",
    "          epochs=EPOCHS, \n",
    "          validation_data=val_dataset,\n",
    "          callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting a Specific Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"dataset/AI Art vs Real Art/Real/RealArt/-man-sits-with-a-woman-on-her-phone-at-a-table-while-looking-at-a-computer_l.jpeg\"\n",
    "\n",
    "img = keras.preprocessing.image.load_img(img_path, \n",
    "                                            target_size=(HEIGHT, WIDTH))\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "# Make predictions\n",
    "predictions = fine_tuned_model.predict(img_array)[0]\n",
    "\n",
    "print(f\"Predictions: {predictions}\")\n",
    "\n",
    "# Interpret the prediction (assuming binary classification with 0 for Real Art and 1 for AI Art)\n",
    "# Ensure predictions is in the correct format\n",
    "if len(predictions.shape) == 1:\n",
    "    predicted_class = 'Real Art' if predictions[0] > 0.5 else 'AI Art'\n",
    "else:\n",
    "    predicted_class = 'Real Art' if predictions[0][0] > 0.5 else 'AI Art'\n",
    "\n",
    "# Create a string with the predicted label\n",
    "result_string = f'The predicted class for the image {img_path} is: {predicted_class}'\n",
    "print(result_string)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting a Random Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "folder_number = random.randint(1, 2)  # Generate a random number between 1-3\n",
    "if folder_number == 1:\n",
    "    dataset_dir = \"dataset/AI Art vs Real Art/AI Art/AiArtData\"\n",
    "else:\n",
    "    dataset_dir = \"dataset/AI Art vs Real Art/Real/RealArt\"\n",
    "\n",
    "print(dataset_dir)\n",
    "file_list = os.listdir(dataset_dir)\n",
    "\n",
    "random_file = random.choice(file_list)\n",
    "image_path = os.path.join(dataset_dir, random_file)\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(image_path, \n",
    "                                            target_size=(HEIGHT, WIDTH))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "# Make predictions\n",
    "predictions = fine_tuned_model.predict(img_array)[0]\n",
    "\n",
    "print(f\"Predictions: {predictions}\")\n",
    "\n",
    "# Interpret the prediction (assuming binary classification with 0 for Real Art and 1 for AI Art)\n",
    "# Ensure predictions is in the correct format\n",
    "if len(predictions.shape) == 1:\n",
    "    predicted_class = 'Real Art' if predictions[0] > 0.5 else 'AI Art'\n",
    "else:\n",
    "    predicted_class = 'Real Art' if predictions[0][0] > 0.5 else 'AI Art'\n",
    "\n",
    "# Create a string with the predicted label\n",
    "result_string = f'The predicted class for the image {random_file} is: {predicted_class}'\n",
    "print(result_string)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization in terms of Epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = fine_tuned_model.history['binary_accuracy']\n",
    "val_acc = fine_tuned_model.history['val_binary_accuracy']\n",
    "\n",
    "loss = fine_tuned_model.history['loss']\n",
    "val_loss = fine_tuned_model.history['val_loss']\n",
    "if stop.stopped_epoch != 0:\n",
    "    epochs_range = range(stop.stopped_epoch+1)\n",
    "else:\n",
    "    epochs_range = range(EPOCHS)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
